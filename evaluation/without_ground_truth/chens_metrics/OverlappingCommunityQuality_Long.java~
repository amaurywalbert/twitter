import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;

public class OverlappingCommunityQuality {

	/**
	 * @param args
	 */
	public static void main(String[] args) {
		String networkFile = args[0];									// Network File		
		String discoveredCommunityFile = args[1];					// Communities detected File
		boolean isUnweighted = false;									// Se rede é Weighted
		boolean isUndirected = false;									// Se rede é Directed
	
		for (String arg : args) {
			if (arg.equals("isUnweighted")) {
				isUnweighted = true;								// Se rede é Unweighted
			} 
			if (arg.equals("isUndirected")) {
				isUndirected = true;								// Se rede é Undirected
			}
		}
		
		System.out.println("isUnweighted = " + isUnweighted + ", isUndirected = " + isUndirected);
		System.out.println("Parâmetro 1 = " + args[0] + ", Parâmetro 2 = " + args[1]);


		// Please look at the function definition for the value of
		// belongingVersion and belongingFunVersion
		long belongingVersion = 1;
		long belongingFunVersion = 1;

//		/*		
		double[] qualities = OverlappingCommunityQuality
				.computeOvQualityWithoutGroundTruth(networkFile, isUnweighted,
						isUndirected, discoveredCommunityFile,
						belongingVersion, belongingFunVersion);
		System.out.println("Q = " + qualities[0] + ", NQ = " + qualities[1]
				+ ", Qds = " + qualities[2] + ", intraEdges = " + qualities[3]
				+ ", intraDensity = " + qualities[4] + ", contraction = "
				+ qualities[5] + ", interEdges = " + qualities[6]
				+ ", expansion = " + qualities[7] + ", conductance = "
				+ qualities[8] + ", fitness = " + qualities[9]
				+ ", modularity degree = " + qualities[10]);

//		 */

		// The same as computeOvQualityWithoutGroundTruth(), except using
		// different data structure

		/*
		double[] qualities = OverlappingCommunityQuality
				.computeOvQualityWithoutGroundTruthWithMap(networkFile,
		 				isUnweighted, isUndirected, discoveredCommunityFile,
		 				belongingVersion, belongingFunVersion);
		 System.out.println("Q = " + qualities[0] + ", NQ = " + qualities[1]
		 		+ ", Qds = " + qualities[2] + ", intraEdges = " + qualities[3]
		 		+ ", intraDensity = " + qualities[4] + ", contraction = "
		 		+ qualities[5] + ", interEdges = " + qualities[6]
		 		+ ", expansion = " + qualities[7] + ", conductance = "
		 		+ qualities[8] + ", fitness = " + qualities[9]
		 		+ ", modularity degree = " + qualities[10]);
		 */

	}

	/**
	 * All the Overlapping community quality metrics (including local and
	 * global) without ground truth communities, with belonging coefficient and
	 * belonging function
	 * 
	 * @param networkFile
	 * @param isUnweighted
	 * @param isUndirected
	 * @param communityFile
	 * @param belongingVersion
	 *            0: fuzzy overlapping; 1: crisp overlapping with belonging
	 *            coefficients being 1/O_i; 2: crisp overlapping with belonging
	 *            coefficients being the strength of the node to the community.
	 * @param belongingFunVersion
	 *            0: average; 1: product; 2: max.
	 * @return
	 */
	public static double[] computeOvQualityWithoutGroundTruth(
			String networkFile, boolean isUnweighted, boolean isUndirected,
			String communityFile, long belongingVersion, long belongingFunVersion) {
		// long startTime = System.currentTimeMillis();

		// Get outgoing network
		HashMap<long, HashMap<long, Double>> outNet = new HashMap<long, HashMap<long, Double>>();
		// Return total weight. if undirected: 2m; if directed: m
		double[] weights = CommunityQuality.getNetwork(networkFile,
				isUnweighted, isUndirected, outNet);
		double totalWeight = weights[0];
		// double maxWeight = weights[1];
		// long numNodes = outNet.size();

		// System.out.println("#node = " + numNodes);

		// If network is directed, get incoming network
		HashMap<long, HashMap<long, Double>> inNet = null;
		if (!isUndirected) {
			inNet = new HashMap<long, HashMap<long, Double>>();
			CommunityQuality.getReversedNetwork(networkFile, isUnweighted,
					isUndirected, inNet);
		}

		// System.out.println("Finish reading the network.");
		Map<long, Set<long>> mapCommunities = CommunityQuality
				.getMapCommunities(communityFile);
		long numComs = mapCommunities.size();
		// System.out.println("#com = " + numComs);

		HashMap<long, HashMap<long, Double>> ovNodeCommunities = OverlappingCommunityQuality
				.getCrispOverlappingNodeCommunities(communityFile);

		if (belongingVersion == 1) {
			// Crisp overlapping with belonging coefficients being 1/O_i
			OverlappingCommunityQuality
					.convertCrispToFuzzyOvCommunityWithNumComs(ovNodeCommunities);
		} else if (belongingVersion == 2) {
			// Crisp overlapping with belonging coefficients being the strength
			// of the node to the community
			OverlappingCommunityQuality
					.convertCrispToFuzzyOvCommunityWithNodeStrength(outNet,
							inNet, isUndirected, mapCommunities,
							ovNodeCommunities);
		}

		// Use type float to save memory
		double[] communitySizes = new double[numComs];
		double[][] communityWeights = new double[numComs][numComs];
		double[][] communityDensities = new double[numComs][numComs];

		// ///////////////////////////////////////////
		for (Map.Entry<long, HashMap<long, Double>> nodeItem : outNet
				.entrySet()) {
			long nodeId = nodeItem.getKey();
			HashMap<long, Double> nodeNbs = nodeItem.getValue();
			HashMap<long, Double> nodeComs = ovNodeCommunities.get(nodeId);

			// Traverse the neighboring nodes of this node
			for (Map.Entry<long, Double> nbItem : nodeNbs.entrySet()) {
				long nbId = nbItem.getKey();
				double weight = nbItem.getValue();
				HashMap<long, Double> nbComs = ovNodeCommunities.get(nbId);

				for (Map.Entry<long, Double> nodeComItem : nodeComs
						.entrySet()) {
					long nodeComId = nodeComItem.getKey();
					double nodeComFactor = nodeComItem.getValue();
					for (Map.Entry<long, Double> nbComItem : nbComs
							.entrySet()) {
						long nbComId = nbComItem.getKey();
						double nbComFactor = nbComItem.getValue();

						// Depends on belongingFunVersion
						if (belongingFunVersion == 0) {
							communityDensities[nodeComId][nbComId] += (nodeComFactor + nbComFactor) / 2;
							communityWeights[nodeComId][nbComId] += weight
									* (nodeComFactor + nbComFactor) / 2;
						} else if (belongingFunVersion == 1) {
							communityDensities[nodeComId][nbComId] += nodeComFactor
									* nbComFactor;
							communityWeights[nodeComId][nbComId] += weight
									* nodeComFactor * nbComFactor;
						} else if (belongingFunVersion == 2) {
							communityDensities[nodeComId][nbComId] += Math.max(
									nodeComFactor, nbComFactor);
							communityWeights[nodeComId][nbComId] += weight
									* Math.max(nodeComFactor, nbComFactor);
						}
					}
				}
			} // node neighbors for
		} // nodes for
			// ///////////////////////////////////////

		for (long iComId = 0; iComId < numComs; ++iComId) {
			Set<long> iCommunity = mapCommunities.get(iComId);

			// Calculate community size with belonging factors
			for (long iNodeId : iCommunity) {
				communitySizes[iComId] += OverlappingCommunityQuality
						.getNodeBelongingFactor(ovNodeCommunities, iNodeId,
								iComId);
			}

			for (long jComId = 0; jComId < numComs; ++jComId) {

				// To save time, if there is no edge between the two
				// communities, we skip this pair
				if (communityWeights[iComId][jComId] == 0) {
					continue;
				}

				Set<long> jCommunity = mapCommunities.get(jComId);

				// Get the numerator and denominator of community density
				// double numerator = 0;
				double denominator = 0;
				for (long iNodeId : iCommunity) {
					// HashMap<Long, Double> iNbs = outNet.get(iNodeId);
					double iFactor = OverlappingCommunityQuality
							.getNodeBelongingFactor(ovNodeCommunities, iNodeId,
									iComId);
					for (long jNodeId : jCommunity) {
						double jFactor = OverlappingCommunityQuality
								.getNodeBelongingFactor(ovNodeCommunities,
										jNodeId, jComId);
						if (iComId == jComId) {
							if (jNodeId != iNodeId) {
								if (belongingFunVersion == 0) {
									denominator += (iFactor + jFactor) / 2;
								} else if (belongingFunVersion == 1) {
									denominator += iFactor * jFactor;
								} else if (belongingFunVersion == 2) {
									denominator += Math.max(iFactor, jFactor);
								}
							}
						} else {
							if (belongingFunVersion == 0) {
								denominator += (iFactor + jFactor) / 2;
							} else if (belongingFunVersion == 1) {
								denominator += iFactor * jFactor;
							} else if (belongingFunVersion == 2) {
								denominator += Math.max(iFactor, jFactor);
							}
						}
					} // jNodeId for
				} // iNodeId for

				if (denominator == 0) {
					communityDensities[iComId][jComId] = 0;
				} else {
					communityDensities[iComId][jComId] = communityDensities[iComId][jComId]
							/ denominator;
				}
			} // j for
		} // i for

		// Compute average community quality of the sample
		double Q = 0;
		double NQ = 0;
		double Qds = 0;
		double intraEdges = 0;
		double intraDensity = 0;
		double contraction = 0;
		double interEdges = 0;
		// double interDensity = 0;
		double expansion = 0;
		double conductance = 0;
		// Fitness function
		double fitnessFunction = 0;

		// Average modularity degree metric
		double D = 0;

		for (long iComId = 0; iComId < numComs; ++iComId) {
			double iCommSize = communitySizes[iComId];
			double inWeights = communityWeights[iComId][iComId];
			double inDensity = communityDensities[iComId][iComId];
			// The number of outgoing edges from nodes inside the community to
			// the nodes ouside this community
			double outWeights = 0;
			// The number of incoming edges from nodes outside the community to
			// the nodes inside this community
			double out_incoming_weights = 0;
			double splitPenalty = 0;

			// The total weight of the subnetwork including the community and
			// its
			// neighboring communities
			double nebComTotalWeight = 0;
			HashSet<long> nebComs = new HashSet<long>();
			nebComs.add(iComId);

			for (long jComId = 0; jComId < numComs; ++jComId) {
				if (jComId != iComId) {
					double wij = communityWeights[iComId][jComId];
					double wji = communityWeights[jComId][iComId];
					outWeights += wij;
					if (wij != 0) {
						nebComs.add(jComId);
					}

					if (!isUndirected) {
						out_incoming_weights += wji;
						if (wji != 0) {
							nebComs.add(jComId);
						}
					}

					// double sp = (wij / totalWeight)
					// * communityDensities[iComId][jComId];
					double sp = wij * communityDensities[iComId][jComId];
					splitPenalty += sp;
				}
			}

			// Calculate nebComTotalWeight
			for (long icom : nebComs) {
				for (long jcom : nebComs) {
					nebComTotalWeight += communityWeights[icom][jcom];
				}
			}

			// System.out.println(inWeights + "\t" + outWeights + "\t"
			// + nebComTotalWeight + "\t" + nebNodeTotalWeight + "\t"
			// + wideNebNodeTotalWeight + "\t" + iCommSize + "\t"
			// + inDensity + "\t" + dc_out + "\t" + dc_out_denominator);

			if (isUndirected) {
				// modularity
				Q += inWeights / totalWeight
						- Math.pow((inWeights + outWeights) / totalWeight, 2);
				// Modularity Density Qds
				Qds += (inWeights / totalWeight)
						* inDensity
						- Math.pow(((inWeights + outWeights) / totalWeight)
								* inDensity, 2) - splitPenalty / totalWeight;

				if (nebComTotalWeight != 0) {
					NQ += inWeights
							/ nebComTotalWeight
							- Math.pow((inWeights + outWeights)
									/ nebComTotalWeight, 2);
				}
			} else {
				Q += inWeights
						/ totalWeight
						- ((inWeights + outWeights) * (inWeights + out_incoming_weights))
						/ Math.pow(totalWeight, 2);
				// Modularity Density Qds
				Qds += (inWeights / totalWeight)
						* inDensity
						- (((inWeights + outWeights) * (inWeights + out_incoming_weights)) / Math
								.pow(totalWeight, 2)) * Math.pow(inDensity, 2)
						- splitPenalty / totalWeight;

				if (nebComTotalWeight != 0) {
					NQ += inWeights
							/ nebComTotalWeight
							- ((inWeights + outWeights) * (inWeights + out_incoming_weights))
							/ Math.pow(nebComTotalWeight, 2);
				}
			}

			// intra-edges
			if (isUndirected) {
				intraEdges += inWeights / 2;
			} else {
				intraEdges += inWeights;
			}
			// contraction: average degree
			if (inWeights == 0 || iCommSize == 0) {
				contraction += 0;
			} else {
				contraction += inWeights / iCommSize;
			}
			// intra-density
			intraDensity += inDensity;
			interEdges += outWeights;
			// inter-density
			// if (numNodes == iCommSize) {
			// interDensity += 0;
			// } else {
			// interDensity += outWeights
			// / (iCommSize * (numNodes - iCommSize));
			// }
			if (outWeights == 0 || iCommSize == 0) {
				expansion += 0;
			} else {
				expansion += outWeights / iCommSize;
			}

			// Avoid that totalInterEdges==0 and communityEdges[i][i]==0
			if (outWeights == 0) {
				conductance += 0;
			} else {
				conductance += outWeights / (inWeights + outWeights);
			}

			// The fitness function
			if (inWeights == 0) {
				fitnessFunction += 0;
			} else {
				double fitness = 0;
				if (isUndirected) {
					fitness = inWeights / (inWeights + 2 * outWeights);
					fitnessFunction += fitness;
				} else {
					fitness = inWeights
							/ (inWeights + outWeights + out_incoming_weights);
					fitnessFunction += fitness;
				}
			}

			// Average modularity degree metric
			if (iCommSize == 0) {
				D += 0;
			} else {
				D += (inWeights - outWeights) / iCommSize;
			}
		} // for

		// for local community detection algorithms
		double[] qualities = { Q, NQ, Qds, intraEdges / numComs,
				intraDensity / numComs, contraction / numComs,
				interEdges / numComs, expansion / numComs,
				conductance / numComs, fitnessFunction / numComs, D };

		// long endTime = System.currentTimeMillis();
		// System.out.println("running time: " + (endTime - startTime) + "ms");

		return qualities;
	}

	/**
	 * All the Overlapping community quality metrics (including local and
	 * global) without ground truth communities, with belonging coefficient and
	 * belonging function
	 * 
	 * It is exactly the same with function computeOvQualityWithoutGroundTruth()
	 * above except it uses HashMap instead of array to save memory for sparse
	 * networks / communities
	 * 
	 * @param networkFile
	 * @param isUnweighted
	 * @param isUndirected
	 * @param communityFile
	 * @param belongingVersion
	 *            0: fuzzy overlapping; 1: crisp overlapping with belonging
	 *            coefficients being 1/O_i; 2: crisp overlapping with belonging
	 *            coefficients being the strength of the node to the community.
	 * @param belongingFunVersion
	 *            0: average; 1: product; 2: max.
	 * @return
	 */
	public static double[] computeOvQualityWithoutGroundTruthWithMap(
			String networkFile, boolean isUnweighted, boolean isUndirected,
			String communityFile, long belongingVersion, long belongingFunVersion) {
		// long startTime = System.currentTimeMillis();

		// Get outgoing network
		HashMap<long, HashMap<long, Double>> outNet = new HashMap<long, HashMap<long, Double>>();
		// Return total weight. if undirected: 2m; if directed: m
		double[] weights = CommunityQuality.getNetwork(networkFile,
				isUnweighted, isUndirected, outNet);
		double totalWeight = weights[0];
		// double maxWeight = weights[1];
		// long numNodes = outNet.size();

		// System.out.println("#node = " + numNodes);

		// If network is directed, get incoming network
		HashMap<long, HashMap<long, Double>> inNet = null;
		if (!isUndirected) {
			inNet = new HashMap<long, HashMap<long, Double>>();
			CommunityQuality.getReversedNetwork(networkFile, isUnweighted,
					isUndirected, inNet);
		}

		// System.out.println("Finish reading the network.");
		Map<long, Set<long>> mapCommunities = CommunityQuality
				.getMapCommunities(communityFile);
		long numComs = mapCommunities.size();
		// System.out.println("#com = " + numComs);

		HashMap<long, HashMap<long, Double>> ovNodeCommunities = OverlappingCommunityQuality
				.getCrispOverlappingNodeCommunities(communityFile);

		if (belongingVersion == 1) {
			// Crisp overlapping with belonging coefficients being 1/O_i
			OverlappingCommunityQuality
					.convertCrispToFuzzyOvCommunityWithNumComs(ovNodeCommunities);
		} else if (belongingVersion == 2) {
			// Crisp overlapping with belonging coefficients being the strength
			// of the node to the community
			OverlappingCommunityQuality
					.convertCrispToFuzzyOvCommunityWithNodeStrength(outNet,
							inNet, isUndirected, mapCommunities,
							ovNodeCommunities);
		}

		// Use type float to save memory
		float[] communitySizes = new float[numComs];
		HashMap<long, HashMap<long, Double>> communityWeights = new HashMap<long, HashMap<long, Double>>();
		// float[][] communityWeights = new float[numComs][numComs];
		HashMap<long, HashMap<long, Double>> communityDensities = new HashMap<long, HashMap<long, Double>>();
		// float[][] communityDensities = new float[numComs][numComs];

		// ///////////////////////////////////////////
		for (Map.Entry<long, HashMap<long, Double>> nodeItem : outNet
				.entrySet()) {
			long nodeId = nodeItem.getKey();
			HashMap<long, Double> nodeNbs = nodeItem.getValue();
			HashMap<long, Double> nodeComs = ovNodeCommunities.get(nodeId);

			// Traverse the neighboring nodes of this node
			for (Map.Entry<Long, Double> nbItem : nodeNbs.entrySet()) {
				long nbId = nbItem.getKey();
				double weight = nbItem.getValue();
				HashMap<long, Double> nbComs = ovNodeCommunities.get(nbId);

				for (Map.Entry<long, Double> nodeComItem : nodeComs
						.entrySet()) {
					long nodeComId = nodeComItem.getKey();
					double nodeComFactor = nodeComItem.getValue();
					if (!communityWeights.containsKey(nodeComId)) {
						communityWeights.put(nodeComId,
								new HashMap<long, Double>());
					}
					if (!communityDensities.containsKey(nodeComId)) {
						communityDensities.put(nodeComId,
								new HashMap<long, Double>());
					}

					for (Map.Entry<long, Double> nbComItem : nbComs
							.entrySet()) {
						long nbComId = nbComItem.getKey();
						double nbComFactor = nbComItem.getValue();
						HashMap<long, Double> comWeight = communityWeights
								.get(nodeComId);
						if (!comWeight.containsKey(nbComId)) {
							comWeight.put(nbComId, 0.0);
						}
						HashMap<long, Double> comDensity = communityDensities
								.get(nodeComId);
						if (!comDensity.containsKey(nbComId)) {
							comDensity.put(nbComId, 0.0);
						}

						// Depends on belongingFunVersion
						if (belongingFunVersion == 0) {
							comDensity.put(nbComId, comDensity.get(nbComId)
									+ (nodeComFactor + nbComFactor) / 2);
							comWeight.put(nbComId, comWeight.get(nbComId)
									+ weight * (nodeComFactor + nbComFactor)
									/ 2);

							// communityDensities[nodeComId][nbComId] +=
							// (nodeComFactor + nbComFactor) / 2;
							// communityWeights[nodeComId][nbComId] += weight
							// * (nodeComFactor + nbComFactor) / 2;
						} else if (belongingFunVersion == 1) {
							comDensity.put(nbComId, comDensity.get(nbComId)
									+ nodeComFactor * nbComFactor);
							comWeight.put(nbComId, comWeight.get(nbComId)
									+ weight * nodeComFactor * nbComFactor);

							// communityDensities[nodeComId][nbComId] +=
							// nodeComFactor
							// * nbComFactor;
							// communityWeights[nodeComId][nbComId] += weight
							// * nodeComFactor * nbComFactor;
						} else if (belongingFunVersion == 2) {
							comDensity.put(nbComId, comDensity.get(nbComId)
									+ Math.max(nodeComFactor, nbComFactor));
							comWeight.put(
									nbComId,
									comWeight.get(nbComId)
											+ weight
											* Math.max(nodeComFactor,
													nbComFactor));

							// communityDensities[nodeComId][nbComId] +=
							// Math.max(
							// nodeComFactor, nbComFactor);
							// communityWeights[nodeComId][nbComId] += weight
							// * Math.max(nodeComFactor, nbComFactor);
						}
					}
				}
			} // node neighbors for
		} // nodes for
			// ///////////////////////////////////////

		for (long iComId = 0; iComId < numComs; ++iComId) {
			Set<long> iCommunity = mapCommunities.get(iComId);

			// Calculate community size with belonging factors
			for (long iNodeId : iCommunity) {
				communitySizes[iComId] += OverlappingCommunityQuality
						.getNodeBelongingFactor(ovNodeCommunities, iNodeId,
								iComId);
			}

			if (!communityWeights.containsKey(iComId)) {
				continue;
			}

			for (long jComId = 0; jComId < numComs; ++jComId) {

				// To save time, if there is no edge between the two
				// communities, we skip this pair
				// if (communityWeights[iComId][jComId] == 0) {
				// continue;
				// }

				if (!communityWeights.get(iComId).containsKey(jComId)) {
					continue;
				}

				Set<long> jCommunity = mapCommunities.get(jComId);

				// Get the numerator and denominator of community density
				// double numerator = 0;
				float denominator = 0;
				for (long iNodeId : iCommunity) {
					// HashMap<long, Double> iNbs = outNet.get(iNodeId);
					double iFactor = OverlappingCommunityQuality
							.getNodeBelongingFactor(ovNodeCommunities, iNodeId,
									iComId);
					for (long jNodeId : jCommunity) {
						double jFactor = OverlappingCommunityQuality
								.getNodeBelongingFactor(ovNodeCommunities,
										jNodeId, jComId);
						if (iComId == jComId) {
							if (jNodeId != iNodeId) {
								if (belongingFunVersion == 0) {
									denominator += (iFactor + jFactor) / 2;
								} else if (belongingFunVersion == 1) {
									denominator += iFactor * jFactor;
								} else if (belongingFunVersion == 2) {
									denominator += Math.max(iFactor, jFactor);
								}
							}
						} else {
							if (belongingFunVersion == 0) {
								denominator += (iFactor + jFactor) / 2;
							} else if (belongingFunVersion == 1) {
								denominator += iFactor * jFactor;
							} else if (belongingFunVersion == 2) {
								denominator += Math.max(iFactor, jFactor);
							}
						}
					} // jNodeId for
				} // iNodeId for

				HashMap<long, Double> comDensity = communityDensities
						.get(iComId);
				if (denominator == 0) {
					comDensity.put(jComId, 0.0);
					// communityDensities[iComId][jComId] = 0;
				} else {
					comDensity
							.put(jComId, comDensity.get(jComId) / denominator);
					// communityDensities[iComId][jComId] =
					// communityDensities[iComId][jComId]
					// / denominator;
				}
			} // j for
		} // i for

		// Compute average community quality of the sample
		double Q = 0;
		double NQ = 0;
		double Qds = 0;
		double intraEdges = 0;
		double intraDensity = 0;
		double contraction = 0;
		double interEdges = 0;
		// double interDensity = 0;
		double expansion = 0;
		double conductance = 0;
		// Fitness function
		double fitnessFunction = 0;

		// Average modularity degree metric
		double D = 0;

		for (long iComId = 0; iComId < numComs; ++iComId) {
			HashMap<long, Double> comWeight = communityWeights.get(iComId);
			HashMap<long, Double> comDensity = communityDensities
					.get(iComId);

			double iCommSize = communitySizes[iComId];
			double inWeights = 0;
			if (comWeight.containsKey(iComId)) {
				inWeights = comWeight.get(iComId);
			}
			// double inWeights = communityWeights[iComId][iComId];
			double inDensity = 0;
			if (comDensity.containsKey(iComId)) {
				inDensity = comDensity.get(iComId);
			}

			// double inDensity = communityDensities[iComId][iComId];
			// The number of outgoing edges from nodes inside the community to
			// the nodes ouside this community
			double outWeights = 0;
			// The number of incoming edges from nodes outside the community to
			// the nodes inside this community
			double out_incoming_weights = 0;
			double splitPenalty = 0;

			// The total weight of the subnetwork including the community and
			// its
			// neighboring communities
			double nebComTotalWeight = 0;
			HashSet<long> nebComs = new HashSet<long>();
			nebComs.add(iComId);

			for (long jComId = 0; jComId < numComs; ++jComId) {
				if (jComId != iComId) {
					double wij = 0;
					if (comWeight.containsKey(jComId)) {
						wij = comWeight.get(jComId);
					}

					// double wij = communityWeights[iComId][jComId];
					double wji = 0;
					if (communityWeights.get(jComId).containsKey(iComId)) {
						wji = communityWeights.get(jComId).get(iComId);
					}
					// double wji = communityWeights[jComId][iComId];
					outWeights += wij;
					if (wij != 0) {
						nebComs.add(jComId);
					}

					if (!isUndirected) {
						out_incoming_weights += wji;
						if (wji != 0) {
							nebComs.add(jComId);
						}
					}

					// double sp = (wij / totalWeight)
					// * communityDensities[iComId][jComId];
					double tmpDensity = 0;
					if (comDensity.containsKey(jComId)) {
						tmpDensity = comDensity.get(jComId);
					}
					double sp = wij * tmpDensity;
					// double sp = wij * communityDensities[iComId][jComId];
					splitPenalty += sp;
				}
			}

			// Calculate nebComTotalWeight
			for (long icom : nebComs) {
				for (long jcom : nebComs) {
					if (communityWeights.get(icom).containsKey(jcom)) {
						nebComTotalWeight += communityWeights.get(icom).get(
								jcom);
					}
					// nebComTotalWeight += communityWeights[icom][jcom];
				}
			}

			// System.out.println(inWeights + "\t" + outWeights + "\t"
			// + nebComTotalWeight + "\t" + nebNodeTotalWeight + "\t"
			// + wideNebNodeTotalWeight + "\t" + iCommSize + "\t"
			// + inDensity + "\t" + dc_out + "\t" + dc_out_denominator);

			if (isUndirected) {
				// modularity
				Q += inWeights / totalWeight
						- Math.pow((inWeights + outWeights) / totalWeight, 2);
				// Modularity Density Qds
				Qds += (inWeights / totalWeight)
						* inDensity
						- Math.pow(((inWeights + outWeights) / totalWeight)
								* inDensity, 2) - splitPenalty / totalWeight;

				if (nebComTotalWeight != 0) {
					NQ += inWeights
							/ nebComTotalWeight
							- Math.pow((inWeights + outWeights)
									/ nebComTotalWeight, 2);
				}
			} else {
				Q += inWeights
						/ totalWeight
						- ((inWeights + outWeights) * (inWeights + out_incoming_weights))
						/ Math.pow(totalWeight, 2);
				// Modularity Density Qds
				Qds += (inWeights / totalWeight)
						* inDensity
						- (((inWeights + outWeights) * (inWeights + out_incoming_weights)) / Math
								.pow(totalWeight, 2)) * Math.pow(inDensity, 2)
						- splitPenalty / totalWeight;

				if (nebComTotalWeight != 0) {
					NQ += inWeights
							/ nebComTotalWeight
							- ((inWeights + outWeights) * (inWeights + out_incoming_weights))
							/ Math.pow(nebComTotalWeight, 2);
				}
			}

			// intra-edges
			if (isUndirected) {
				intraEdges += inWeights / 2;
			} else {
				intraEdges += inWeights;
			}
			// contraction: average degree
			if (inWeights == 0 || iCommSize == 0) {
				contraction += 0;
			} else {
				contraction += inWeights / iCommSize;
			}
			// intra-density
			intraDensity += inDensity;
			interEdges += outWeights;
			// inter-density
			// if (numNodes == iCommSize) {
			// interDensity += 0;
			// } else {
			// interDensity += outWeights
			// / (iCommSize * (numNodes - iCommSize));
			// }
			if (outWeights == 0 || iCommSize == 0) {
				expansion += 0;
			} else {
				expansion += outWeights / iCommSize;
			}

			// Avoid that totalInterEdges==0 and communityEdges[i][i]==0
			if (outWeights == 0) {
				conductance += 0;
			} else {
				conductance += outWeights / (inWeights + outWeights);
			}

			// The fitness function
			if (inWeights == 0) {
				fitnessFunction += 0;
			} else {
				double fitness = 0;
				if (isUndirected) {
					fitness = inWeights / (inWeights + 2 * outWeights);
					fitnessFunction += fitness;
				} else {
					fitness = inWeights
							/ (inWeights + outWeights + out_incoming_weights);
					fitnessFunction += fitness;
				}
			}

			// Average modularity degree metric
			if (iCommSize == 0) {
				D += 0;
			} else {
				D += (inWeights - outWeights) / iCommSize;
			}
		} // for

		double[] qualities = { Q, NQ, Qds, intraEdges / numComs,
				intraDensity / numComs, contraction / numComs,
				interEdges / numComs, expansion / numComs,
				conductance / numComs, fitnessFunction / numComs, D };

		// long endTime = System.currentTimeMillis();
		// System.out.println("running time: " + (endTime - startTime) + "ms");

		return qualities;
	}
	

	/**
	 * Compute entropy according to probability
	 * 
	 * @param p
	 * @return
	 */
	public static double logUtil(double p) {
		double value = 0;
		if (p > 0) {
			value = -p * (Math.log10(p) / Math.log10(2));
		}

		return value;
	}

	/**
	 * Return the belonging factor of a node to a community
	 * 
	 * @param ovNodeCommunities
	 * @param nodeId
	 * @param comId
	 * @return
	 */
	public static double getNodeBelongingFactor(
			HashMap<long, HashMap<long, Double>> ovNodeCommunities,
			long nodeId, long comId) {
		double factor = 0;
		HashMap<Long, Double> communities = ovNodeCommunities.get(nodeId);
		if (communities.containsKey(comId)) {
			factor = communities.get(comId);
		}
		return factor;
	}

	/**
	 * 
	 * @param ovNodeCommunities
	 */
	public static void convertCrispToFuzzyOvCommunityWithNumComs(
			HashMap<long, HashMap<Long, Double>> ovNodeCommunities) {
		for (Map.Entry<long, HashMap<long, Double>> nodeItem : ovNodeCommunities
				.entrySet()) {
			HashMap<long, Double> communities = nodeItem.getValue();
			double factor = 1.0 / communities.size();

			for (Map.Entry<long, Double> comItem : communities.entrySet()) {
				comItem.setValue(factor);
			}
		}
	}

	/**
	 * For undirected networks, only consider outgoing edges; for directed
	 * networks, consider both outgoing and incoming edges. Pay much attension
	 * to the overlapping situation.
	 * 
	 * @param outNet
	 * @param inNet
	 * @param isUndirected
	 * @param mapCommunities
	 * @param ovNodeCommunities
	 */
	public static void convertCrispToFuzzyOvCommunityWithNodeStrength(
			HashMap<long, HashMap<long, Double>> outNet,
			HashMap<long, HashMap<long, Double>> inNet,
			boolean isUndirected, Map<long, Set<long>> mapCommunities,
			HashMap<long, HashMap<long, Double>> ovNodeCommunities) {
		for (Map.Entry<long, HashMap<long, Double>> nodeItem : ovNodeCommunities
				.entrySet()) {
			long nodeId = nodeItem.getKey();
			HashMap<long, Double> communities = nodeItem.getValue();

			// Get the node strength
			HashMap<long, Double> outNodeNbs = outNet.get(nodeId);
			double totalNodeWeight = 0;
			for (Map.Entry<long, Double> nbItem : outNodeNbs.entrySet()) {
				long nbId = nbItem.getKey();
				double weight = nbItem.getValue();

				// Traverse each community this node belongs to to get the node
				// strength for this node to that community
				for (Map.Entry<long, Double> comItem : communities
						.entrySet()) {
					long comId = comItem.getKey();
					if (mapCommunities.get(comId).contains(nbId)) {
						comItem.setValue(comItem.getValue() + weight);
						totalNodeWeight += weight;
					}
				}
			}

			// if directed
			if (!isUndirected) {
				HashMap<long, Double> inNodeNbs = inNet.get(nodeId);
				for (Map.Entry<long, Double> nbItem : inNodeNbs.entrySet()) {
					long nbId = nbItem.getKey();
					double weight = nbItem.getValue();

					// Traverse each community this node belongs to to get the
					// node
					// strength for this node to that community
					for (Map.Entry<long, Double> comItem : communities
							.entrySet()) {
						long comId = comItem.getKey();
						if (mapCommunities.get(comId).contains(nbId)) {
							comItem.setValue(comItem.getValue() + weight);
							totalNodeWeight += weight;
						}
					}
				}
			}

			// divided by the total node weight
			for (Map.Entry<long, Double> comItem : communities.entrySet()) {
				// if (comItem.getValue() == 0 && totalNodeWeight == 0) {
				// System.out.println("NaN");
				// }

				if (comItem.getValue() == 0 || totalNodeWeight == 0) {
					comItem.setValue(0.0);
				} else {
					comItem.setValue(comItem.getValue() / totalNodeWeight);
				}
			}
		}
	}

	/**
	 * The id of communities start from 0
	 * 
	 * @param communityFile
	 * @return
	 */
	public static HashMap<long, HashMap<long, Double>> getCrispOverlappingNodeCommunities(
			String communityFile) {
		HashMap<long, HashMap<long, Double>> nodeCommunities = new HashMap<long, HashMap<long, Double>>();
		try {
			BufferedReader br = new BufferedReader(new InputStreamReader(
					new FileInputStream(communityFile)));
			String tmp = null;
			String[] nodes = null;
			// The id of communities start from 0
			long count = 0;

			while ((tmp = br.readLine()) != null) {
				tmp = tmp.trim();
				tmp = tmp.replaceAll("\\s+", " ");
				nodes = tmp.split(" ");

				for (long i = 0; i < nodes.length; ++i) {
					long node = Long.parseLong(nodes[i]);

					if (!nodeCommunities.containsKey(node)) {
						nodeCommunities.put(node,
								new HashMap<long, Double>());
					}

					HashMap<long, Double> communities = nodeCommunities
							.get(node);
					communities.put(count, 0.0);
				}

				++count;
			}

			br.close();
		} catch (FileNotFoundException e) {
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		}

		return nodeCommunities;
	}

	/**
	 * The id of communities start from 0
	 * 
	 * @param communityFile
	 * @return
	 */
	public static HashMap<long, HashSet<long>> getOverlappingNodeCommunities(
			String communityFile) {
		HashMap<long, HashSet<long>> nodeCommunities = new HashMap<long, HashSet<long>>();
		try {
			BufferedReader br = new BufferedReader(new InputStreamReader(
					new FileInputStream(communityFile)));
			String tmp = null;
			String[] nodes = null;
			// The id of communities start from 0
			long count = 0;

			while ((tmp = br.readLine()) != null) {
				tmp = tmp.trim();
				tmp = tmp.replaceAll("\\s+", " ");
				nodes = tmp.split(" ");

				for (long i = 0; i < nodes.length; ++i) {
					long node = Long.parseLong(nodes[i]);

					if (!nodeCommunities.containsKey(node)) {
						nodeCommunities.put(node, new HashSet<long>());
					}

					HashSet<long> communities = nodeCommunities.get(node);
					communities.add(count);
				}

				++count;
			}

			br.close();
		} catch (FileNotFoundException e) {
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		}

		return nodeCommunities;
	}

}
